# 판다스

- 판다스 불러오기
    - import pandas as pd
- 시리즈 만들기
    - menu = pd.Series([’비빔밥’, ‘김치찌개’, ‘된장찌개’]) 대문자주의
    
    |  | **0** |
    | --- | --- |
    | **0** | 비빔밥 |
    | **1** | 김치찌개 |
    | **2** | 된장찌개 |
    
    **dtype:** object
    
    - price = pd.Series([10000, 9000, 8000])
    
    |  | **0** |
    | --- | --- |
    | **0** | 10000 |
    | **1** | 9000 |
    | **2** | 8000 |
    
    **dtype:** int64
    
- 데이터 프레임 만들기
    - pd.DataFrame({”메뉴” : menu, “가격 : price}) 대문자 주의

| **메뉴** | **가격** |
| --- | --- |
| **0** | 비빔밥 |
| **1** | 김치찌개 |
| **2** | 된장찌개 |
- 데이터 프레임 한번에 만들기
    - df = pd.DataFrame({”메뉴” : [’비빔밥’, ‘김치찌개’, ‘된장찌개’],

                                                    “가격” : [10000, 9000, 8000],

                                                     “원산지” : [’국내산’, ‘국내산’, ‘국내산’]})

|  | **메뉴** | **가격** | **원산지** |
| --- | --- | --- | --- |
| **0** | 비빔밥 | 10000 | 국내산 |
| **1** | 김치찌개 | 9000 | 국내산 |
| **2** | 된장찌개 | 8000 | 국내산 |
- 시리즈 선택
    - df[’메뉴’]
    
    | **메뉴** |
    | --- |
    | **0** |
    | **1** |
    | **2** |
    
    **dtype:** object
    
- 데이터프레임 선택
    - df[[’메뉴’, ‘가격’]]
    
    |  | **메뉴** | **가격** |
    | --- | --- | --- |
    | **0** | 비빔밥 | 10000 |
    | **1** | 김치찌개 | 9000 |
    | **2** | 된장찌개 | 8000 |
- 데이터프레임 선택 (변수사용)
    - cols = [’메뉴’, ‘가격’]
        
        df[cols]
        
        대괄호 한개 → 시리즈 불러오기 / 대괄호 두개 → 데이터 프레임 불러오기
        
        | **메뉴** | **가격** |
        | --- | --- |
        | **0** | 비빔밥 |
        | **1** | 김치찌개 |
        | **2** | 된장찌개 |
- csv로 저장
    - df = pd.DataFrame({”메뉴” : [’비빔밥’, ‘김치찌개’, ‘된장찌개’],

                                                    “가격” : [10000, 9000, 8000],

                                                     “원산지” : [’국내산’, ‘국내산’, ‘국내산’]})

- df.to_csv(’temp.scv’) ← 인덱스 자동 생김
- df.to_csv(’cafe.csv’, index=False) ← 인덱스 자동생성 없이 저장
- 불러오기
    - **temp_df = pd.read_csv(’temp.csv’)**
    - temp_df.head() ← 미리보기

- 데이터 샘플 확인 : 앞에서부터 n개 (기본5개)
    - df.head(2)
- 데이터 샘플 확인 : 뒤에서부터 n개 (기본5개)
    - df.tail(3)
- 샘플 확인 : 랜덤으로 n개
    - df.sample(3)
- 데이터 프레임 크기 확인 : 행, 열 **(괄호없음 주의)**
    - df.shape
- 컬럼 형태 확인 : 널값확인, 타입확인 문자: object, 정수 :int64, 실수 : float64
    - df.info()
- 상관관계 확인 : 숫자만 가능
    - df.corr(numeric_only=True)
- select_dtype 메서드

df.select_dtype(include=’int’) ← 정수형만 필터링

df.select_dtype(exclude=’int’) ← 정수형이 아닌것만 필터링

- set_index 메서드

df .set_index(’datetime’) ← 기존의 0부터 시작하는 숫자 대신 datetime이라는 컬럼을 인덱스로 사용하겠다

- filter 메서드

df.filter(like=’00:00:00’, axis=0) ← axis=0행, axis=1열로 행 열 모두 필터링 가능

df.filter(items=[’humidity’,’windspeed’]) ← 포함하는 행/열 필터링

df.filter(regex=’in.s’) ← 정규표현식 필터링 가능 (정규표현식은 몰라도됨)

- rename 메서드

df.rename({변경전:변경후}), axis=1)

```
df_car = pd.DataFrame({
    "car":['Sedan','SUV','Sedan','SUV','SUV','SUV','Sedan','Sedan','Sedan','Sedan','Sedan'],
    "size":['S','M','S','S','M','M','L','S','S', 'M','S']
})
```

- 중복 값이 있는 데이터 항목 종류 수 확인
    - df_car.unique()
    
    |  | **0** |
    | --- | --- |
    | **car** | 2 |
    | **size** | 3 |
    
    **dtype:** int64
    
- 항목 종류 확인
    - print(df_car[’car’].unique())
    
            print(df_car[’size’].unique())
    
    ['Sedan' 'SUV']
    ['S' 'M' 'L']
    
- 항목별 개수 확인
    - print(df_car[’car’].value_counts())
    
            print(df_car[’size’].value_counts())
    
    car
    Sedan    7
    SUV      4
    Name: count, dtype: int64
    size
    S    6
    M    4
    L    1
    Name: count, dtype: int64
    
- 기초 통계 확인
    - df.describe() ← 숫자 기초통계 확인
    
    |  | **가격** | **칼로리** |
    | --- | --- | --- |
    | **count** | 7.000000 | 7.000000 |
    | **mean** | 5028.571429 | 101.428571 |
    | **std** | 631.702160 | 99.402980 |
    | **min** | 4000.000000 | 0.000000 |
    | **25%** | 4750.000000 | 15.000000 |
    | **50%** | 5000.000000 | 110.000000 |
    | **75%** | 5400.000000 | 160.000000 |
    | **max** | 5900.000000 | 250.000000 |
    - df.describe(include=”O”) 대문자O ← 문자열 있을때 count, unique, top, freq 확인
    
    |  | **car** | **size** |
    | --- | --- | --- |
    | **count** | 11 | 11 |
    | **unique** | 2 | 3 |
    | **top** | Sedan | S |
    | **freq** | 7 | 6 |
- 자료형 변환
    - df[’가격’] = df[’가격’].astype(’int’)
- 새로운 컬럼 추가 ← ★df[’컬럼명’]만 하면됨★
    - df[’new’] = 0 (값은 0)
    
    |  | **메뉴** | **가격** | **칼로리** | **new** |
    | --- | --- | --- | --- | --- |
    | **0** | 아메리카노 | 4500 | 10 | 0 |
    | **1** | 카페라떼 | 5000 | 110 | 0 |
    - discount = 0.2
    
    df[’할인가’] = df[’가격’] * (1-discount)
    
    |  | **메뉴** | **가격** | **칼로리** | **new** | **할인가** |
    | --- | --- | --- | --- | --- | --- |
    | **0** | 아메리카노 | 4500 | 10 | 0 | 3600.0 |
    | **1** | 카페라떼 | 5000 | 110 | 0 | 4000.0 |
- 데이터 삭제 ★★★axis=0 : 행방향, axis=1 : 열방향 표시 필수★★★
    - df = df.drop(1,axis=0)
    - df = df.drop(’칼로리’, axis=1)

- query 메서드

문자열로 행 필터링

df.query(’bill_length_nm > 55’)

df.query(’bill_length_nm > 55 and species == “Gentoo”’)

(@를 사용하여 외부변수 참조 가능)

length = 55

species = ‘Gentoo’

df.query(’bill_length_nm >= @length and species == @species’)

df.query(’island.str.contains(”oe”), engine = ‘python’)

df.query(’species.str.endwith(”e”)’, engine = ‘python’)

filtering = [”Adelie”, “Chinstrap”]

df.query(’species.isin(@filtering)’, engine = ‘python’)

- 인덱싱, 슬라이싱 (행→열 순)

loc, iloc 인덱싱은 리스트인덱싱이니까 대괄호 사용

- df.loc[’행’,’열’] ← 행,열 명 (인덱스, 컬럼명)
- df.iloc[행,열] ← 인덱스 번호 ← 인덱스, 컬럼명 제외하고

★★★ : 쓸때는 맨마지막 숫자 제외 , : 안쓸때는 제외안함★★★

★★loc으로 특정열 조회하고싶을때는 [’1열’, ‘3열’] 이렇게 리스트형식으로 제시★★

- loc[조건문] → 조건만족하는 필터링 가능
    
    ex ) df.loc[df.[’season’]==2]
    
    - df.loc[ : , ‘가격’] ← 모든행 + 가격열
    - df.iloc[ : , 1] ← 모든행 + 1열
    - df.loc[’라떼’:’모카’ , ‘가격’:’칼로리’] ← 라떼~모카 행 + 가격~칼로리 열
    - df.iloc[ 1:3, 1: ] ← 1~2행 + 1~끝까지 열

- 결측치에 데이터 추가
    - df.loc[0, “원산지”] = ‘콜롬비아’
    - df.loc[2:3, :원산지”] = ‘과테말라’
- 리스트 형태로 행 추가
    - df.loc[’시즌’] = [’크리스마스라떼’, 6000, 300, ‘한국’]
    
    | **메뉴** | **가격** | **칼로리** | **원산지** |
    | --- | --- | --- | --- |
    | **5** | 밀크티 | 5900 | 210 |
    | **6** | 녹차 | 5300 | 0 |
    | **시즌** | 크리스마스라떼 | 6000 | 300 |
- 딕셔너리 형태로 행 추가
    - df.loc[7] = {’메뉴’ : ‘딴짓커피’, ‘가격’ : 2000, ‘칼로리’ : 20}
    
    |  | **메뉴** | **가격** | **칼로리** | **원산지** |
    | --- | --- | --- | --- | --- |
    | **6** | 녹차 | 5300 | 0 | NaN |
    | **시즌** | 크리스마스라떼 | 6000 | 300 | 한국 |
    | **7** | 딴짓커피 | 2000 | 20 | NaN |
    
- 인덱스 기준 정렬 ascending=True 오름차순/ False 내림차순

★True False 대문자 주의★

- df.sort_index(ascending=False)
- df.sort_values(’메뉴’,ascending=False)
- 가격과 메뉴 기준 정렬
    - df = df.sort_values([’가격’, ‘메뉴’], ascending=[False,True])
- 정렬 후 인덱스 새로 만들기
    - df.reset_index(drop=True) drop=True ← 기존 인덱스 지우기

- 필터링

★필터링 시 true=1, false=0으로 결과나오니까 sum으로 구하기★

★df[cond1] ← cond1이 true인 값만 표시해라★

- df[’칼로리’] < 50
- 1개 조건으로 필터링 ← cond 라는 변수 사용
    - cond = df[’칼로리’] < 50
    
           df[cond]
    
           df[~cond] ← 칼로리 ≥ 50 인 데이터 필터링
    
- 2개 이상 조건 사용  & ← and ㅣ ← or
    
    cond1 = df[’가격’] >= 5000
    
    cond2 = df[’칼로리’] > 100
    
    df[cond1 & cond2]
    
    df[cond1 ㅣ cond2]
    
- 문자열 조건
    
    cond = (df[’원산지’] == “과테말라”)
    
    df[cond]
    
    df[’메뉴’].isin([’녹차’]) ← 녹차가 들어가있으면 true, 아니면 false
    
    cond = df[’메뉴’].isin([’녹차’])
    
    df[cond]
    
    box = [’녹차’, ‘카푸치노’, ‘카페라떼’]
    
    cond = df[’메뉴’].isin(box)
    
    df[cond] ← 녹차, 카푸치노, 카페라떼가 들어가있는것만 필터링
    

- 결측치 확인
    - df.isnull() ← 결측치 존재시 True, True=1, False=0
    - df.isnull().sum() ← 결측치 존재시 결측치 갯수가 합해짐
- 결측값 채우기
    - df[’원산지’] = df[’원산지’].fillna(’코스타리카’) ← 결측치에 코스타리카 를삽입
- dropna 메서드

df = df.dropna(subset = ‘Review’, axis=0) ←Review 열에서 결측치 삭제

- 값 변경
    - df = df.replace(’아메리카노’, ‘룽고’) ← 아메리카노를 룽고로 변경
    - df = df.str.replace(’아메’,’룽고’) ← 일부 글자열만 변경 (룽고리카노)
        
        숫자일때는 str 사용 불가
        
    - loc로 값 변경
        
        df.loc[6, ‘원산지’] = ‘대한민국’
        
    - 이벤트가 전체 1000으로 변경
        
        df.loc[1:2, ‘이벤트가’] = 1000 ← 1, 2외에는 결측값이 생성됨
        
    - 문자열 분리
    
          df[’A’].str.split()[0] → A열에서 단어를 띄어쓰기 기준으로 분리, 0(첫번째 행) 선택
    
          df[’A].str.split().str[0] → A열에서 단어를 띄어쓰기 기준으로 분리, 첫번째 단어 선택
    
    - 문자 검색
        
        df[’A’].str.contains(’기본’) ← A열에서 ‘기본’이 들어간 데이터 검색
        
        df[’기본포함유무’] = df[’A’].str.contains(’기본’) ← 데이터프레임에 A열에대해서 기본포함유무 열 삽입
        
        cf) isin ← 풀네임이 똑같아야 true 반환 , 여러개 단어 동시에 찾기 가능
        
             contains ← 일부 단어만 똑같아도 ture 반환, 여러개 단어 동시에 찾기 불가능
        
    - df[’문자길이’] = df[’A’].str.len() ←A행의 문자길이를 반환하는 열 생성
    - change  = {’룽고’:’아메리카노’, ‘그린티’:’녹차’} ← 룽고를 아메리카노로, 그린티를 녹차로 변경
        
        df = df.replace(change)
        
    - 대문자, 소문자 변경
        
        df[’C’] = df[’C’].str.upper()
        
        df[’C’] = df[’C’].str.lower()
        
    - 공백 제거
    
            df[’C’] = df[’C’].str.replace(” “,””)
    
    - df[’C’].str[1:3] ← C열의 문자열 중 2~3번째 문자열 반환
    - df[’C’][1:3] ← C열중 1~2행만 반환
    
- 맵 합수 사용
    
    import pandas as pd
    
    df = pd.DataFrame({’만족도’: [’만족’, ‘보통’, ‘불만’, ‘보통’, ‘만족’]})
    
    mapping = {’만족’ : 3, ‘보통’ : 2, ‘불만’ : 1}
    
    df[’만족도_숫자’] = df[’만족도’].map(mapping)
    
- 행의 수 출력
    - print(len(df))
    - print(df.shape[0]) ← shape 행 열 다불러와서 0(행) 만 출력

- 조건에 맞는 행 수 출력
    - cond = df[’가격’] > 5000
        
        print(sum(cond))
        
        print(len(df[cond]))
        
- 컬럼별로 합계 구하기
    
    df.sum(numeric_only=True)
    
    행별로 합계 구하기
    
    df.sum(axis=1, numeric_only=True)
    
    ★★★sum() 할 때 axis=0 : 컬럼별 합계, axis=1 : 행별 합계★★★
    

- 함수 사용 ★★★뒤에 () 붙여야함★★★
    
    최대값 df[’가격’].max()
    
    최소값 df[’가격’].min()
    
    평균값 df[’가격’].mean()
    
    중앙값 df[’가격’].median
    
    합계 df[’가격’].sum()
    
    표준편차 df[’가격’].std()
    
    분산 df[’가격’].var()
    
    분위수 25% df[’가격’.quantile(.25))
    
    분위수 75% df[’가격’.quantile(.75))
    
    하위 25%데이터 
    
    cond = df[’가격’].quantile(.25) > df[’가격’]
    
    df[cond]
    
    상위 25%데이터
    
    cond = df[’가격’].quantile(.75) < df[’가격’]
    
    df[cond]
    
    - quantile 메서드 + for문
    
    quantile = [0, 0.2, 0.4, 0.6, 0.8, 1]
    
    for i in quantile:
    
    q = df[’Total_Review’].quantile(i)
    
    print(f’quantile({i}) is {q}’)
    
    최빈값 df[’원산지’.mode()[0] ← 최빈값 여러개 나올 수 있으니까 그 중 첫번째값 찾으려고 [0] 삽입
    
    ★mode 는 맨 뒤에 [0] 해야함★
    
    df[’가격’].idxmax() ← 가격 중 가장 큰 값의 인덱스번호 반환
    
    max_ind = df[’가격’].idxmax()
    
    df.loc[max_ind] ← 가격이 가장 큰 인덱스의 데이터프레임 불러옴
    
                         5
    
    메뉴 밀크티
    
    가격 5900
    
    칼로리 210
    
    원산지 코스타리카
    
    df.loc[max_ind, ‘메뉴’] ← 가격이 가장 큰 것의 메뉴이름만 반환
    
    위에서 탑3 df.nlargest(3, ‘가격’)
    
    아래서 탑2 df.nsmallest(2, ‘가격’)
    

- applt 적용하여 새로운 컬럼 생성

★★★def cal( ) ← ( ) 안에 있는게 파라미터를 넣는 입구!★★★

★★★return 값을 바로 적용시켜야함★★★

def cal(x):

if x >= 100:

return “No”

else:

return “Yes”

df[’먹어도 될까요’] = df[’칼로리’].apply(cal) ← 칼로리 열에 cal 함수를 apply 하여 먹어도 될까요 라는 열 생성

| **메뉴** | **메뉴** | **가격** | **칼로리** | **원산지** | **이벤트가** | **먹어도 될까요** |
| --- | --- | --- | --- | --- | --- | --- |
| **0** | 아메리카노 | 4500 | 10 | 콜롬비아 | NaN | Yes |
| **1** | 카페라떼 | 5000 | 110 | 코스타리카 | 1000.0 | No |
| **2** | 카페모카 | 5500 | 250 | 과테말라 | 1000.0 | No |
| **3** | 카푸치노 | 5000 | 110 | 과테말라 | NaN | No |
| **4** | 에스프레소 | 4000 | 20 | 코스타리카 | NaN | Yes |
| **5** | 밀크티 | 5900 | 210 | 코스타리카 | NaN | No |
| **6** | 녹차 | 5300 | 0 | 대한민국 | NaN | Yes |
| **7** | 딴짓커피 | 2000 | 20 | 코스타리카 | NaN | Yes |
- melt 함수 사용
    
    ```
    import pandas as pd
    df = pd.DataFrame({'Name': {0: '쿼카', 1: '알파카', 2: '시바견'},
                       '수학': {0: 90, 1: 93, 2: 85},
                       '영어': {0: 92, 1: 84, 2: 86},
                       '국어': {0: 91, 1: 94, 2: 83},})
    ```
    

| **Name** | **수학** | **영어** | **국어** |
| --- | --- | --- | --- |
| **0** | 쿼카 | 90 | 92 |
| **1** | 알파카 | 93 | 84 |
| **2** | 시바견 | 85 | 86 |

pd. melt(df, id_vars=[’Name’])

|  | **Name** | **variable** | **value** |
| --- | --- | --- | --- |
| **0** | 쿼카 | 수학 | 90 |
| **1** | 알파카 | 수학 | 93 |
| **2** | 시바견 | 수학 | 85 |
| **3** | 쿼카 | 영어 | 92 |
| **4** | 알파카 | 영어 | 84 |
| **5** | 시바견 | 영어 | 86 |
| **6** | 쿼카 | 국어 | 91 |
| **7** | 알파카 | 국어 | 94 |
| **8** | 시바견 | 국어 | 83 |

pd.melt(df, id_vars=[’Name’], var_name=’과목’, value_name=’점수’)

|  | **Name** | **과목** | **점수** |
| --- | --- | --- | --- |
| **0** | 쿼카 | 수학 | 90 |
| **1** | 알파카 | 수학 | 93 |
| **2** | 시바견 | 수학 | 85 |
| **3** | 쿼카 | 영어 | 92 |
| **4** | 알파카 | 영어 | 84 |
| **5** | 시바견 | 영어 | 86 |
| **6** | 쿼카 | 국어 | 91 |
| **7** | 알파카 | 국어 | 94 |
| **8** | 시바견 | 국어 | 83 |

- groupby 메서드

#기본 사용법

df.groupby(’sex’)[’survived’’].mean()

sex

female 0.742038

male     0.188908

df.groupby([’sex’,’class’])[’survived’].mean()

sex          class

female    First              0.968085

                Second        0.921053

                Third             0.500000

male        First              0.387542

                 Second        0.159325

                 Third             0.135413

#변수 별 별도 통계 연산도 가능

df.groupby([’sex’,’class’])[’survived’].agg([’mean’,’count’])

df.groupby([’sex’,’class’])[[’survived’,’age’]].agg({’survived:’mean’, ‘age’:’man’})

#사용자 정의 함수도 사용 가능

def get_IQR(data):

3rd = data.quantile(.75)

1st = data.quantile(.25)

return ((3rd-1st)*1.5)

df.groupby([’sex’,’class’])[’age’].apply(get_IQR)

#결측치를 그룹별 평균값으로 대체

df.isna().sum() ← 결측치 갯수 확인

df.groupby(’species’)[[’bill_length_mm’, ‘bill_depth_mm’, ‘flipper_length_mm’, ‘body_mass_g’]].mean() ← 그룹별 평균값 확인

df.groupby(’species’)[[’bill_length_mm’, ‘bill_depth_mm’, ‘flipper_length_mm’, ‘body_mass_g’]].apply(lambda x : x.fillna(x.mean())) ← 결측치를 그룹별 평균값으로 대체

#인자로 열 외에 다른 형태 데이터 전달

    group  value

0          A           1

1          A           1

2          A           1

3          B           10

4          B           10

df.groupby([0,0,1,1,1])[’value’].sum() 

0      2

1       21

s = pd.series([False,False,True,True,True])

df.groupby(s)[’value’].sum()

False      2

True       21

df.groupby([’원산지’, ‘칼로리’]).mean(numeric_only=True) : 원산지→ 칼로리기준으로 평균내기

|  |  | **가격** | **이벤트가** |
| --- | --- | --- | --- |
| **원산지** | **칼로리** |  |  |
| **과테말라** | **110** | 5000.0 | NaN |
|  | **250** | 5500.0 | 1000.0 |
| **대한민국** | **0** | 5300.0 | NaN |
| **코스타리카** | **20** | 3000.0 | NaN |
|  | **110** | 5000.0 | 1000.0 |
|  | **210** | 5900.0 | NaN |
| **콜롬비아** | **10** | 4500.0 | NaN |

          df.groupby([’원산지’, ‘메뉴]’).agg([’mean’,’sum’]) : 원산지→메뉴 기준으로 평균과 합계 내기

|  |  | 가격 |  | 칼로리 |  | 이벤트가 |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
|  |  | **mean** | **sum** | **mean** | **sum** | **mean** | **sum** |
| **원산지** | **메뉴** |  |  |  |  |  |  |
| **과테말라** | **카페모카** | 5500.0 | 5500 | 250.0 | 250 | 1000.0 | 1000.0 |
|  | **카푸치노** | 5000.0 | 5000 | 110.0 | 110 | NaN | 0.0 |
| **대한민국** | **녹차** | 5300.0 | 5300 | 0.0 | 0 | NaN | 0.0 |
| **코스타리카** | **딴짓커피** | 2000.0 | 2000 | 20.0 | 20 | NaN | 0.0 |
|  | **밀크티** | 5900.0 | 5900 | 210.0 | 210 | NaN | 0.0 |
|  | **에스프레소** | 4000.0 | 4000 | 20.0 | 20 | NaN | 0.0 |
|  | **카페라떼** | 5000.0 | 5000 | 110.0 | 110 | 1000.0 | 1000.0 |
| **콜롬비아** | **아메리카노** | 4500.0 | 4500 | 10.0 | 10 | NaN | 0.0 |

              df.groupby([’원산지’, ‘칼로리’]).mean(numeric_only=True).reset_index()

|  | **원산지** | **칼로리** | **가격** | **이벤트가** |
| --- | --- | --- | --- | --- |
| **0** | 과테말라 | 110 | 5000.0 | NaN |
| **1** | 과테말라 | 250 | 5500.0 | 1000.0 |
| **2** | 대한민국 | 0 | 5300.0 | NaN |
| **3** | 코스타리카 | 20 | 3000.0 | NaN |
| **4** | 코스타리카 | 110 | 5000.0 | 1000.0 |
| **5** | 코스타리카 | 210 | 5900.0 | NaN |
| **6** | 콜롬비아 | 10 | 4500.0 | NaN |
- Transform 사용

```
df = pd.DataFrame({
    '과일': ['딸기', '블루베리', '딸기', '블루베리', '딸기', '블루베리', '딸기', '블루베리'],
    '가격': [1000, None, 1500, None, 2000, 2500, None, 1800]  # 결측값 포함
})
df
```

|  | 과일 | 가격 |
| --- | --- | --- |
| 0 | 딸기 | 1000.0 |
| 1 | 블루베리 | NaN |
| 2 | 딸기 | 1500.0 |
| 3 | 블루베리 | NaN |
| 4 | 딸기 | 2000.0 |
| 5 | 블루베리 | 2500.0 |
| 6 | 딸기 | NaN |
| 7 | 블루베리 | 1800.0 |

과일 평균 가격 구하기

price = df.groupby(’과일’)[’가격’].tranform(”mean”) → (과일)을 [가격]열로 

|  | 가격 |
| --- | --- |
| 0 | 1500.0 |
| 1 | 2150.0 |
| 2 | 1500.0 |
| 3 | 2150.0 |
| 4 | 1500.0 |
| 5 | 2150.0 |
| 6 | 1500.0 |
| 7 | 2150.0 |

**dtype:** float64

결측치 채우기

df[’가격’] = df[’가격’].fillna(price)

df

|  | 과일 | 가격 |
| --- | --- | --- |
| 0 | 딸기 | 1000.0 |
| 1 | 블루베리 | 2150.0 |
| 2 | 딸기 | 1500.0 |
| 3 | 블루베리 | 2150.0 |
| 4 | 딸기 | 2000.0 |
| 5 | 블루베리 | 2500.0 |
| 6 | 딸기 | 1500.0 |
| 7 | 블루베리 | 1800.0 |

```
df = pd.DataFrame({
    '과일': ['딸기', '블루베리', '딸기', '블루베리', '딸기', '블루베리', '딸기', '블루베리'],
    '등급': ['B', 'B', 'A', 'A', 'A', 'A', 'B', 'B'],  # 새로운 그룹 추가
    '가격': [1000, None, 1500, None, 2000, 2500, None, 1800]  # 결측값 포함
})
df
```

|  | 과일 | 등급 | 가격 |
| --- | --- | --- | --- |
| 0 | 딸기 | B | 1000.0 |
| 1 | 블루베리 | B | NaN |
| 2 | 딸기 | A | 1500.0 |
| 3 | 블루베리 | A | NaN |
| 4 | 딸기 | A | 2000.0 |
| 5 | 블루베리 | A | 2500.0 |
| 6 | 딸기 | B | NaN |
| 7 | 블루베리 | B | 1800.0 |

과일/등급별 평균 가격 구하기

price = df.groupby([’과일’, ‘등급])[’가격’].transform(”mean”)

 ★★★함수 → 소괄호, 열 표시 → 대괄호, 리스트 → 대괄호★★★

|  | 가격 |
| --- | --- |
| 0 | 1000.0 |
| 1 | 1800.0 |
| 2 | 1750.0 |
| 3 | 2500.0 |
| 4 | 1750.0 |
| 5 | 2500.0 |
| 6 | 1000.0 |
| 7 | 1800.0 |

**dtype:** float64

결측치 채우기

df[’가격’] = df[’가격’].fillna(price)

df

|  | 과일 | 등급 | 가격 |
| --- | --- | --- | --- |
| 0 | 딸기 | B | 1000.0 |
| 1 | 블루베리 | B | 1800.0 |
| 2 | 딸기 | A | 1500.0 |
| 3 | 블루베리 | A | 2500.0 |
| 4 | 딸기 | A | 2000.0 |
| 5 | 블루베리 | A | 2500.0 |
| 6 | 딸기 | B | 1000.0 |
| 7 | 블루베리 | B | 1800.0 |
- unstack 활용

```
import pandas as pd

coffee_data = {
    '커피종류': ['아메리카노', '아메리카노', '아메리카노', '라떼', '라떼', '라떼'],
    '컵크기': ['Small', 'Medium', 'Large', 'Small', 'Medium', 'Large'],
    '판매량': [120, 150, 200, 100, 130, 180]
}
df = pd.DataFrame(coffee_data)
df
```

|  | 커피종류 | 컵크기 | 판매량 |
| --- | --- | --- | --- |
| 0 | 아메리카노 | Small | 120 |
| 1 | 아메리카노 | Medium | 150 |
| 2 | 아메리카노 | Large | 200 |
| 3 | 라떼 | Small | 100 |
| 4 | 라떼 | Medium | 130 |
| 5 | 라떼 | Large | 180 |

groupby 적용

grouped = df.groupby([’커피종류’, ‘컵크기’])[’판매량’].sum()

grouped

|  |  | 판매량 |
| --- | --- | --- |
| 커피종류 | 컵크기 |  |
| 라떼 | Large | 180 |
|  | Medium | 130 |
|  | Small | 100 |
| 아메리카노 | Large | 200 |
|  | Medium | 150 |
|  | Small | 120 |

**dtype:** int64

컵크기를 컬럼으로 변환

grouped.unstack() ← 기본 level : -1 맨 뒤쪽에있는 컬럼(컵크기)활용

| 컵크기 | Large | Medium | Small |
| --- | --- | --- | --- |
| 커피종류 |  |  |  |
| 라떼 | 180 | 130 | 100 |
| 아메리카노 | 200 | 150 | 120 |

커피종류를 컬럼으로 변환

grouped.unstack(level=0)

| 커피종류 | 라떼 | 아메리카노 |
| --- | --- | --- |
| 컵크기 |  |  |
| Large | 180 | 200 |
| Medium | 130 | 150 |
| Small | 100 | 120 |

- 데이터 합치기

```
import pandas as pd

# 에피타이저 메뉴
appetizer = pd.DataFrame({
    'Menu': ['Salad', 'Soup', 'Bread'],
    'Price': [5000, 3000, 2000]
})

# 메인 메뉴
main = pd.DataFrame({
    'Menu': ['Steak', 'Pasta', 'Chicken'],
    'Price': [15000, 12000, 10000]
})
print(appetizer)
print(main)
```

    `Menu  Price
0  Salad   5000
1   Soup   3000
2  Bread   2000
      Menu  Price
0    Steak  15000
1    Pasta  12000
2  Chicken  10000`

두 메뉴를 수직으로 연결

full_menu = pd.concat([appetizer, main], ignore_index=True) : ignore_index=True → 인덱스 번호 0부터다시시작

|  | Menu | Price |
| --- | --- | --- |
| 0 | Salad | 5000 |
| 1 | Soup | 3000 |
| 2 | Bread | 2000 |
| 3 | Steak | 15000 |
| 4 | Pasta | 12000 |
| 5 | Chicken | 10000 |

두 메뉴를 좌우로 연결

full_menu = pd.concat([appetizer, main], axis=1)

|  | Menu | Price | Menu | Price |
| --- | --- | --- | --- | --- |
| 0 | Salad | 5000 | Steak | 15000 |
| 1 | Soup | 3000 | Pasta | 12000 |
| 2 | Bread | 2000 | Chicken | 10000 |

```
# 메뉴와 가격
price = pd.DataFrame({
    'Menu': ['Salad', 'Soup', 'Steak', 'Pasta'],
    'Price': [5000, 3000, 15000, 12000]
})

# 메뉴와 칼로리
cal = pd.DataFrame({
    'Menu': ['Soup', 'Steak', 'Pasta','Salad'],
    'Calories': [100, 500, 400, 150]
})
```

두 데이터프레임을 ‘Menu’를 기준으로 병합

menu_info = pd.merge(price, cal, on=’Menu’)

menu_info

|  | Menu | Price | Calories |
| --- | --- | --- | --- |
| 0 | Salad | 5000 | 150 |
| 1 | Soup | 3000 | 100 |
| 2 | Steak | 15000 | 500 |
| 3 | Pasta | 12000 | 400 |

- 피벗 테이블

```
import pandas as pd

# 직원별 부서 및 급여 정보
data = {
    '이름': ['서아', '다인', '채아', '예담', '종현', '태헌'],
    '부서': ['개발', '기획', '개발', '기획', '개발', '기획'],
    '급여': [3000, 3200, 3100, 3300, 2900, 3100]
}
df = pd.DataFrame(data)
print("[원본 데이터]")
print(df)
```

`[원본 데이터]
   이름  부서    급여
0  서아  개발  3000
1  다인  기획  3200
2  채아  개발  3100
3  예담  기획  3300
4  종현  개발  2900
5  태헌  기획  3100`

부서별 평균 급여 계산

pt = df.pivot_table(index=’부서’, values=’급여’, aggfunc=’mean’)

print(”/n[부서별 평균 급여]”) → /n은 줄바꿈 

print(pt)

`[부서별 평균 급여]
        급여
부서        
개발  3000.0
기획  3200.0`

```
# 부서와 직급별 급여 정보
data = {
    '부서': ['개발', '기획', '기획', '기획', '개발', '개발'],
    '직급': ['대리', '과장', '대리', '과장', '대리', '과장'],
    '급여': [3000, 4000, 3200, 4200, 3500, 4500]
}
df = pd.DataFrame(data)
print("[원본 데이터]")
print(df)
```

`[원본 데이터]
   부서  직급    급여
0  개발  대리  3000
1  기획  과장  4000
2  기획  대리  3200
3  기획  과장  4200
4  개발  대리  3500
5  개발  과장  4500`

부서 및 직급별 급여 합계 계산

pt = df.pivot_table(index=’부서’, columns=’직급’, values=’급여’, afffunc=’sum)

print(”/n[부서 및 직급별 급여 합계]”)

print(pt)

`[부서 및 직급별 급여 합계]
직급    과장    대리
부서            
개발  4500  6500
기획  8200  3200`

```
# 다양한 집계를 위한 데이터셋
import pandas as pd

df = pd.DataFrame({
    "구분": ["전자", "전자", "전자", "전자", "전자", "가전", "가전", "가전", "가전"],
    "유형": ["일반", "일반", "일반", "특수", "특수", "일반", "일반", "특수", "특수"],
    "크기": ["소형", "대형", "대형", "소형", "소형", "대형", "소형", "소형", "대형"],
    "수량": [1, 2, 2, 3, 3, 4, 5, 6, 7],
    "금액": [2, 4, 5, 5, 6, 6, 8, 9, 9]
})
print(df)
```

   `구분  유형  크기  수량  금액
0  전자  일반  소형   1   2
1  전자  일반  대형   2   4
2  전자  일반  대형   2   5
3  전자  특수  소형   3   5
4  전자  특수  소형   3   6
5  가전  일반  대형   4   6
6  가전  일반  소형   5   8
7  가전  특수  소형   6   9
8  가전  특수  대형   7   9`

단일 값에 대해 집계

pt = df.pivot_table(index=[’구분’, ‘유형’], columns=’크기’, values=’수량’, aggfunc=’sum’, fill_value=0) 

pt

|  | 크기 | 대형 | 소형 |
| --- | --- | --- | --- |
| 구분 | 유형 |  |  |
| 가전 | 일반 | 4.0 | 5.0 |
|  | 특수 | 7.0 | 6.0 |
| 전자 | 일반 | 4.0 | 1.0 |
|  | 특수 | 0 | 6.0 |

여러 열에 대해 각기 다른 집계 함수 적용

pt = df.pivot_table(index=[’구분’,’크기’], values=[’수량’, ‘금액’], aggfuc={’수량’: “mean”, ‘금액’: ‘mean”}

|  |  | 금액 | 수량 |
| --- | --- | --- | --- |
| 구분 | 크기 |  |  |
| 가전 | 대형 | 7.500000 | 5.500000 |
|  | 소형 | 8.500000 | 5.500000 |
| 전자 | 대형 | 4.500000 | 2.000000 |
|  | 소형 | 4.333333 | 2.333333 |

하나의 열에 대해 여러 집계 함수를 동시에 적용

pt = df.pivot_table(index=[’구분’, ‘크기’], values=[’수량’, ‘금액’], aggfunc={’수량’ : “mean”, ‘금액’ : [”min”, “max”, “mean”]})

pt.reset_index()

|  | 구분 | 크기 | 금액 |  |  | 수량 |
| --- | --- | --- | --- | --- | --- | --- |
|  |  |  | max | mean | min | mean |
| 0 | 가전 | 대형 | 9 | 7.500000 | 6 | 5.500000 |
| 1 | 가전 | 소형 | 9 | 8.500000 | 8 | 5.500000 |
| 2 | 전자 | 대형 | 5 | 4.500000 | 4 | 2.000000 |
| 3 | 전자 | 소형 | 6 | 4.333333 | 2 | 2.333333 |

시계열 데이터

```
import pandas as pd
data = {
    'Date1': ['2024-02-17', '2024-02-18', '2024-02-19'],
    'Date2': ['2024:02:17', '2024:02:18', '2024:02:19'],
    'Date3': ['24/02/17', '24/02/18', '24/02/19'],
    'Date4': ['02/17/2024', '02/18/2024', '02/19/2024'],
    'Date5': ['17-Feb-2024', '18-Feb-2024', '19-Feb-2024'],
    'Date6': ['2024년02월17일', '2024년02월18일', '2024년02월19일'],
    'DateTime1': ['24-02-17 11:45:30', '24-02-18 12:55:45', '24-02-19 13:30:15'],
    'DateTime2': ['2024-02-17 11-45-30', '2024-02-18 12-55-45', '2024-02-19 13-30-15'],
    'DateTime3': ['02/17/2024 11:45:30 AM', '02/18/2024 12:55:45 PM', '02/19/2024 01:30:15 PM'],
    'DateTime4': ['17 Feb 2024 11:45:30', '18 Feb 2024 12:55:45', '19 Feb 2024 13:30:15']
}

df = pd.DataFrame(data)
df.to_csv("date.csv", index=False)
df
```

|  | Date1 | Date2 | Date3 | Date4 | Date5 | Date6 | DateTime1 | DateTime2 | DateTime3 | DateTime4 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | 2024-02-17 | 2024:02:17 | 24/02/17 | 02/17/2024 | 17-Feb-2024 | 2024년02월17일 | 24-02-17 11:45:30 | 2024-02-17 11-45-30 | 02/17/2024 11:45:30 AM | 17 Feb 2024 11:45:30 |
| 1 | 2024-02-18 | 2024:02:18 | 24/02/18 | 02/18/2024 | 18-Feb-2024 | 2024년02월18일 | 24-02-18 12:55:45 | 2024-02-18 12-55-45 | 02/18/2024 12:55:45 PM | 18 Feb 2024 12:55:45 |
| 2 | 2024-02-19 | 2024:02:19 | 24/02/19 | 02/19/2024 | 19-Feb-2024 | 2024년02월19일 | 24-02-19 13:30:15 | 2024-02-19 13-30-15 | 02/19/2024 01:30:15 PM | 19 Feb 2024 13:30:15 |

데이터 불러오기

df = pd.read_csv(”date.csv”)

df

|  | Date1 | Date2 | Date3 | Date4 | Date5 | Date6 | DateTime1 | DateTime2 | DateTime3 | DateTime4 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | 2024-02-17 | 2024:02:17 | 24/02/17 | 02/17/2024 | 17-Feb-2024 | 2024년02월17일 | 24-02-17 11:45:30 | 2024-02-17 11-45-30 | 02/17/2024 11:45:30 AM | 17 Feb 2024 11:45:30 |
| 1 | 2024-02-18 | 2024:02:18 | 24/02/18 | 02/18/2024 | 18-Feb-2024 | 2024년02월18일 | 24-02-18 12:55:45 | 2024-02-18 12-55-45 | 02/18/2024 12:55:45 PM | 18 Feb 2024 12:55:45 |
| 2 | 2024-02-19 | 2024:02:19 | 24/02/19 | 02/19/2024 | 19-Feb-2024 | 2024년02월19일 | 24-02-19 13:30:15 | 2024-02-19 13-30-15 | 02/19/2024 01:30:15 PM | 19 Feb 2024 13:30:15 |

Date1

df = pd.read_csv(”date.csv”)

print(df[’Date1’])

df[’Date1’] = pd.to_datetime(df[’Date1’]) → 문자열데이터를 시계열데이터로 변경

print(df[’Date1’])

`0    2024-02-17
1    2024-02-18
2    2024-02-19
Name: Date1, dtype: object
0   2024-02-17
1   2024-02-18
2   2024-02-19
Name: Date1, dtype: datetime64[ns]`

Date2(year 4자리 : %Y)

df = pd.read_csv(”date.csv”)

print(df[’Date2’])

df[’Date2’] = pd.to_datetime(df[’Date2’], format=”%Y:%m:%d”) ← 포맷으로 년 월 일 지정해줘야 오류가 안남

`0    2024:02:17
1    2024:02:18
2    2024:02:19
Name: Date2, dtype: object
0   2024-02-17
1   2024-02-18
2   2024-02-19
Name: Date2, dtype: datetime64[ns]`

Date3(year 2자리: %y)

df = pd.read_csv(”date.csv”)

print(df[’Date3’])

df[’Date3’] = pd.to_datetime(df[’Date3’], format=”%y/%m/%d”)

print(df[’Date3’])

`0    24/02/17
1    24/02/18
2    24/02/19
Name: Date3, dtype: object
0   2024-02-17
1   2024-02-18
2   2024-02-19
Name: Date3, dtype: datetime64[ns]`

Date4, Date5

→ format 함수 없이도 시계열자료로 변경 가능

Date6

df = pd.read_csv(”date.csv”)

print(df[’Date6’])

df[’Date6’] = pd.to_datetime(df[’Date6’], format = “%Y년%m월%d일”)

print(df[’Date6’])

`0    2024년02월17일
1    2024년02월18일
2    2024년02월19일
Name: Date6, dtype: object
0   2024-02-17
1   2024-02-18
2   2024-02-19
Name: Date6, dtype: datetime64[ns]`

DateTime1

df=pd.read_csv(”date.csv”)

print(df[’DateTime1’])

df[’DateTime1] = pd.to_datetime(df[’DateTime1’], format=”%y-%m-%d %H:%M:%S”) ← 시간은 모두 대문자

print(df[’DateTime1’])

`0    24-02-17 11:45:30
1    24-02-18 12:55:45
2    24-02-19 13:30:15
Name: DateTime1, dtype: object
0   2024-02-17 11:45:30
1   2024-02-18 12:55:45
2   2024-02-19 13:30:15
Name: DateTime1, dtype: datetime64[ns]`

DateTime2

df=pd.read_csv(”date.csv”)

print(df[’DateTime2’])

df[’DateTime2] = pd.to_datetime(df[’DateTime2’], format=”%Y-%m-%d %H-%M-%S”)

print(df[’DateTime2’])

`0    2024-02-17 11-45-30
1    2024-02-18 12-55-45
2    2024-02-19 13-30-15
Name: DateTime2, dtype: object
0   2024-02-17 11:45:30
1   2024-02-18 12:55:45
2   2024-02-19 13:30:15
Name: DateTime2, dtype: datetime64[ns]`

DateTime3, DateTime4 → format 함수 없이도 시계열 데이터로 정상적으로 변환됨

- 년,월,일 시간,분,초 추출 → 시계열 데이터로 변경되어야 사용 가능

df[’year’] = df[’DateTime4’].dt.year

df[’month’] = df[’DateTime4’].dt.month

df[’day’] = df[’DateTime4’].dt.day

df[’hour’] = df[’DateTime4’].dt.hour

df[’minute’] = df[’DateTime4’].dt.minute

df[’second’] = df[’DateTime4’].dt.second

df

|  | Date1 | Date2 | Date3 | Date4 | Date5 | Date6 | DateTime1 | DateTime2 | DateTime3 | DateTime4 | year | month | day | hour | minute | second |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | 2024-02-17 | 2024:02:17 | 24/02/17 | 02/17/2024 | 17-Feb-2024 | 2024년02월17일 | 24-02-17 11:45:30 | 2024-02-17 11-45-30 | 02/17/2024 11:45:30 AM | 2024-02-17 11:45:30 | 2024 | 2 | 17 | 11 | 45 | 30 |
| 1 | 2024-02-18 | 2024:02:18 | 24/02/18 | 02/18/2024 | 18-Feb-2024 | 2024년02월18일 | 24-02-18 12:55:45 | 2024-02-18 12-55-45 | 02/18/2024 12:55:45 PM | 2024-02-18 12:55:45 | 2024 | 2 | 18 | 12 | 55 | 45 |
| 2 | 2024-02-19 | 2024:02:19 | 24/02/19 | 02/19/2024 | 19-Feb-2024 | 2024년02월19일 | 24-02-19 13:30:15 | 2024-02-19 13-30-15 | 02/19/2024 01:30:15 PM | 2024-02-19 13:30:15 | 2024 | 2 | 19 | 13 | 30 | 15 |

- 요일 추출하기 0:월 ~ 6:일

df[’DateTime4’].dt.dayofweek

`0    5
1    6
2    0
Name: DateTime4, dtype: int64`

- 주말 찾기

★★★df[’is주말’] = df[’DateTime4’].dt.dayofweek >= 5★★★

df

|  | Date1 | Date2 | Date3 | Date4 | Date5 | Date6 | DateTime1 | DateTime2 | DateTime3 | DateTime4 | year | month | day | hour | minute | second | is주말 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 0 | 2024-02-17 | 2024:02:17 | 24/02/17 | 02/17/2024 | 17-Feb-2024 | 2024년02월17일 | 24-02-17 11:45:30 | 2024-02-17 11-45-30 | 02/17/2024 11:45:30 AM | 2024-02-17 11:45:30 | 2024 | 2 | 17 | 11 | 45 | 30 | True |
| 1 | 2024-02-18 | 2024:02:18 | 24/02/18 | 02/18/2024 | 18-Feb-2024 | 2024년02월18일 | 24-02-18 12:55:45 | 2024-02-18 12-55-45 | 02/18/2024 12:55:45 PM | 2024-02-18 12:55:45 | 2024 | 2 | 18 | 12 | 55 | 45 | True |
| 2 | 2024-02-19 | 2024:02:19 | 24/02/19 | 02/19/2024 | 19-Feb-2024 | 2024년02월19일 | 24-02-19 13:30:15 | 2024-02-19 13-30-15 | 02/19/2024 01:30:15 PM | 2024-02-19 13:30:15 | 2024 | 2 | 19 | 13 | 30 | 15 | False |
- 시계열 데이터 추가학습

#시계열 데이터로 변환 + 해당 시계열 데이터를 인덱스로 활용

df[’Date’] = pd.to_datetime(df[’Date’])

df = df.set_index(’Date’)

#시계열 행 슬라이싱 가능

df[’1980-12-13’ : ‘1980-12-18’]

df[’2015-02’ : ‘2015-02’] ← 2월 데이터 전부 반환

#resample 메서드

df.resample(’7d).mean() ← 7일동안의 평균을 반환

B ← 영업일

d ← 모든일
